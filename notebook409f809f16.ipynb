{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\n\nlines = open('../input/chatbot-data/cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8',\n             errors='ignore').read().split('\\n')\n\nconvers = open('../input/chatbot-data/cornell movie-dialogs corpus/movie_conversations.txt', encoding='utf-8',\n             errors='ignore').read().split('\\n')\n\n\nexchn = []\nfor conver in convers:\n    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n\ndiag = {}\nfor line in lines:\n    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n\n## delete\ndel(lines, convers, conver, line)\n\nquestions = []\nanswers = []\n\nfor conver in exchn:\n    for i in range(len(conver) - 1):\n        questions.append(diag[conver[i]])\n        answers.append(diag[conver[i+1]])\n\n## delete\ndel(diag, exchn, conver, i)\n\n\n###############################\n#        max_len = 13         #\n###############################\n\nsorted_ques = []\nsorted_ans = []\nfor i in range(len(questions)):\n    if len(questions[i]) < 13:\n        sorted_ques.append(questions[i])\n        sorted_ans.append(answers[i])\n\n\n\ndef clean_text(txt):\n    txt = txt.lower()\n    txt = re.sub(r\"i'm\", \"i am\", txt)\n    txt = re.sub(r\"he's\", \"he is\", txt)\n    txt = re.sub(r\"she's\", \"she is\", txt)\n    txt = re.sub(r\"that's\", \"that is\", txt)\n    txt = re.sub(r\"what's\", \"what is\", txt)\n    txt = re.sub(r\"where's\", \"where is\", txt)\n    txt = re.sub(r\"\\'ll\", \" will\", txt)\n    txt = re.sub(r\"\\'ve\", \" have\", txt)\n    txt = re.sub(r\"\\'re\", \" are\", txt)\n    txt = re.sub(r\"\\'d\", \" would\", txt)\n    txt = re.sub(r\"won't\", \"will not\", txt)\n    txt = re.sub(r\"can't\", \"can not\", txt)\n    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n    return txt\n\nclean_ques = []\nclean_ans = []\n\nfor line in sorted_ques:\n    clean_ques.append(clean_text(line))\n        \nfor line in sorted_ans:\n    clean_ans.append(clean_text(line))\n\n\n\n## delete\ndel(answers, questions, line)\n\n\n\nfor i in range(len(clean_ans)):\n    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n\n\n\n###############################\n#                             #\n###############################\n\ndel(sorted_ans, sorted_ques)\n\n\n## trimming\nclean_ans=clean_ans[:30000]\nclean_ques=clean_ques[:30000]\n## delete\n\n\n###  count occurences ###\nword2count = {}\n\nfor line in clean_ques:\n    for word in line.split():\n        if word not in word2count:\n            word2count[word] = 1\n        else:\n            word2count[word] += 1\nfor line in clean_ans:\n    for word in line.split():\n        if word not in word2count:\n            word2count[word] = 1\n        else:\n            word2count[word] += 1\n\n## delete\ndel(word, line)\n\n\n###  remove less frequent ###\nthresh = 5\n\nvocab = {}\nword_num = 0\nfor word, count in word2count.items():\n    if count >= thresh:\n        vocab[word] = word_num\n        word_num += 1\n        \n## delete\ndel(word2count, word, count, thresh)       \ndel(word_num)        \n\n\n\nfor i in range(len(clean_ans)):\n    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n\n\n\ntokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\nx = len(vocab)\nfor token in tokens:\n    vocab[token] = x\n    x += 1\n    \n    \n\nvocab['cameron'] = vocab['<PAD>']\nvocab['<PAD>'] = 0\n\n## delete\ndel(token, tokens) \ndel(x)\n\n### inv answers dict ###\ninv_vocab = {w:v for v, w in vocab.items()}\n\n\n\n## delete\ndel(i)\n\n\n\nencoder_inp = []\nfor line in clean_ques:\n    lst = []\n    for word in line.split():\n        if word not in vocab:\n            lst.append(vocab['<OUT>'])\n        else:\n            lst.append(vocab[word])\n        \n    encoder_inp.append(lst)\n\ndecoder_inp = []\nfor line in clean_ans:\n    lst = []\n    for word in line.split():\n        if word not in vocab:\n            lst.append(vocab['<OUT>'])\n        else:\n            lst.append(vocab[word])        \n    decoder_inp.append(lst)\n\n### delete\ndel(clean_ans, clean_ques, line, lst, word)\n\n\n\n\n\n\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nencoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\ndecoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n\n\n\n\ndecoder_final_output = []\nfor i in decoder_inp:\n    decoder_final_output.append(i[1:]) \n\ndecoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')\n\n\ndel(i)\n\nfrom tensorflow.keras.utils import to_categorical\ndecoder_final_output = to_categorical(decoder_final_output, len(vocab))\n\n\n\nprint(decoder_final_output.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n\n\nenc_inp = Input(shape=(13, ))\ndec_inp = Input(shape=(13, ))\n\n\nVOCAB_SIZE = len(vocab)\nembed = Embedding(VOCAB_SIZE+1, output_dim=50, \n                  input_length=13,\n                  trainable=True                  \n                  )\n\n\nenc_embed = embed(enc_inp)\nenc_lstm = LSTM(400, return_sequences=True, return_state=True)\nenc_op, h, c = enc_lstm(enc_embed)\nenc_states = [h, c]\n\n\n\ndec_embed = embed(dec_inp)\ndec_lstm = LSTM(400, return_sequences=True, return_state=True)\ndec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n\ndense = Dense(VOCAB_SIZE, activation='softmax')\n\ndense_op = dense(dec_op)\n\nmodel = Model([enc_inp, dec_inp], dense_op)\n\n\n\n\nmodel.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n\nmodel.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=15)\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\n\n\nenc_model = Model([enc_inp], enc_states)\n\n\n\n# decoder Model\ndecoder_state_input_h = Input(shape=(400,))\ndecoder_state_input_c = Input(shape=(400,))\n\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\n\ndecoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n                                    initial_state=decoder_states_inputs)\n\n\ndecoder_states = [state_h, state_c]\n\n\ndec_model = Model([dec_inp]+ decoder_states_inputs,\n                                      [decoder_outputs]+ decoder_states)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n\nfrom keras.preprocessing.sequence import pad_sequences\nprint(\"##########################################\")\nprint(\"#       start chatting ver. 1.0          #\")\nprint(\"##########################################\")\n\n\nprepro1 = \"\"\nwhile prepro1 != 'q':\n    prepro1  = input(\"you : \")\n    ## prepro1 = \"Hello\"\n\n    prepro1 = clean_text(prepro1)\n    ## prepro1 = \"hello\"\n\n    prepro = [prepro1]\n    ## prepro1 = [\"hello\"]\n\n    txt = []\n    for x in prepro:\n        # x = \"hello\"\n        lst = []\n        for y in x.split():\n            ## y = \"hello\"\n            try:\n                lst.append(vocab[y])\n                ## vocab['hello'] = 454\n            except:\n                lst.append(vocab['<OUT>'])\n        txt.append(lst)\n\n    ## txt = [[454]]\n    txt = pad_sequences(txt, 13, padding='post')\n\n    ## txt = [[454,0,0,0,.........13]]\n\n    stat = enc_model.predict( txt )\n\n    empty_target_seq = np.zeros( ( 1 , 1) )\n     ##   empty_target_seq = [0]\n\n\n    empty_target_seq[0, 0] = vocab['<SOS>']\n    ##    empty_target_seq = [255]\n\n    stop_condition = False\n    decoded_translation = ''\n\n    while not stop_condition :\n\n        dec_outputs , h, c= dec_model.predict([ empty_target_seq] + stat )\n        decoder_concat_input = dense(dec_outputs)\n        ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n\n        sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n        ## sampled_word_index = [2]\n\n        sampled_word = inv_vocab[sampled_word_index] + ' '\n\n        ## inv_vocab[2] = 'hi'\n        ## sampled_word = 'hi '\n\n        if sampled_word != '<EOS> ':\n            decoded_translation += sampled_word  \n\n        if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n            stop_condition = True \n\n        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n        empty_target_seq[ 0 , 0 ] = sampled_word_index\n        ## <SOS> - > hi\n        ## hi --> <EOS>\n        stat = [h, c]  \n\n    print(\"chatbot attention : \", decoded_translation )\n    print(\"==============================================\")  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}